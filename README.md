# Basic-Projects

I. 2020A2PS1777P_Decision_Tree
   Dataset used: spambase_data.csv
   Q1) Creating a decision stump and finding the majority class and error.
   Q2) Creating a decision tree classifier using entropy to measure the quality of split.
   Q3) Comparing 2 decision trees based on their corresponding criterion (gini or entropy)
   Q4) Finding optimal tree depth (corresponding to maximum accuracy).
   Q5) Found feature importance from the trained model and rebuilt the model using the top 10 features only to check for information loss.
   
II. 2020A2PS1777P_KNN
   Dataset used: spambase_data.csv
   Q1) Normalized the dataset (using min-max normalization) and applied 3-NN using both Euclidean and Manhattan distance
   Q2) Trained both the 3-NN classifiers and compared their accuracy
   Q3) Finding the accuracy of a rote learner (k=1)
   Q4) Finding the accuracy of models for K ranging from 1 to 20 using euclidean distance and k-fold cross-validation.
   Q5) Plot the graph between K and corresponding accuracy to find optimal value of K.
   Q6) Performed Q4 and Q5 with Manhattan distance measure.
   Q7) Implemented weighted K-NN model. Used k-fold cross-validation for train-test split.
   Q8) Found the optimal K value for weighted KNN
   
III. 2020A2PS1777P_Ensemble
     Dataset used: bank_data.csv, car_data.csv
     Performed Label Encoding of categorical features
     Q1) Dropped attribute 'current_act'
     Q2)
     Q3)
     Q4)
     Q5)
     
